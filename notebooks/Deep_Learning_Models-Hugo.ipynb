{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6411cd",
   "metadata": {},
   "source": [
    "Yesterday (02/09/2024), the group completed the ML models to create the baseline models for both financial agent and sentiment classification. Sasha's notebook, and models are the ones we will use as a baseline. These can be found below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299b5c50",
   "metadata": {},
   "source": [
    "# Initial Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2346004",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INSERT SASHAS BASELINE MODELS #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483364c2",
   "metadata": {},
   "source": [
    "# Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e82cf5",
   "metadata": {},
   "source": [
    "Today, we will try to improve the performance of the baseline models using the following:\n",
    "- LSTM\n",
    "- BERT\n",
    "- FinBert\n",
    "- Roberta\n",
    "\n",
    "The first step is to load the data again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83feea",
   "metadata": {},
   "source": [
    "## Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c3ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f737bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.23.4 put in requirments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cae1662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the agent classification data\n",
    "bis_data_aud = pd.read_csv('../raw_data/Labelled/Audiences/BIS_prelabelled.txt', header=0)\n",
    "ecb_data_aud = pd.read_csv('../raw_data/Labelled/Audiences/ECB_prelabelled.txt', header=0)\n",
    "fed_data_aud = pd.read_csv('../raw_data/Labelled/Audiences/FED_prelabelled.txt', header=0, engine='python')\n",
    "\n",
    "# load in the sentiment classifcation data\n",
    "bis_data_sent = pd.read_csv('../raw_data/Labelled/Sentiment/BIS_prelabelled_sent.txt', header=0)\n",
    "ecb_data_sent = pd.read_csv('../raw_data/Labelled/Sentiment/ECB_prelabelled_sent.txt', header=0)\n",
    "fed_data_sent = pd.read_csv('../raw_data/Labelled/Sentiment/FED_prelabelled_sent.txt', header=0)\n",
    "fed_data_sent = fed_data_sent.drop('audience', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff2225c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>governmental policy including that of the fede...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in light of the difficulties and uncertainties...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this means keeping the federal funds rate at i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>any decision to move in this direction therefo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6the developments in the payments area are par...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  governmental policy including that of the fede...          0\n",
       "1  in light of the difficulties and uncertainties...          0\n",
       "2  this means keeping the federal funds rate at i...          1\n",
       "3  any decision to move in this direction therefo...          1\n",
       "4  6the developments in the payments area are par...          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the sentiment classifcation into one df\n",
    "sentiment_data = pd.concat([fed_data_sent, ecb_data_sent, bis_data_sent])\n",
    "sentiment_data = sentiment_data.reset_index(drop=True)\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac27205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parsed_Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the unemployment rate last year averaged just ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in addition the end of extended unemployment i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for persons with only a high school diploma bo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>but once the shortterm unemployed pool is depl...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is almost the same level as the structura...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Parsed_Text  label\n",
       "0  the unemployment rate last year averaged just ...    0.0\n",
       "1  in addition the end of extended unemployment i...    0.0\n",
       "2  for persons with only a high school diploma bo...    0.0\n",
       "3  but once the shortterm unemployed pool is depl...    0.0\n",
       "4  this is almost the same level as the structura...    0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the agent classifcation into one df\n",
    "agent_data = pd.concat([bis_data_aud, fed_data_aud, ecb_data_aud])\n",
    "agent_data = agent_data.reset_index(drop=True)\n",
    "agent_data = agent_data.drop(columns=['Unnamed: 0'])\n",
    "agent_data = agent_data.dropna()\n",
    "agent_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e57cdc",
   "metadata": {},
   "source": [
    "## Long-Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15e5bbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 12:08:08.796764: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-03 12:08:08.800881: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-03 12:08:08.845755: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-03 12:08:08.893396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-03 12:08:08.927898: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-03 12:08:08.938589: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-03 12:08:09.000048: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-03 12:08:10.767414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Masking, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c76df",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f17de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sentiment_data['text']\n",
    "y = sentiment_data['sentiment']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=69, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea94549",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences=X_train, vector_size=60, min_count=10, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11325c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "097d37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ffc091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the training and test sentences\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)\n",
    "\n",
    "\n",
    "# Pad the training and test embedded sentences\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=200)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f701aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_shape = (X_train_pad.shape[1], X_train_pad.shape[2])\n",
    "from tensorflow.keras import layers\n",
    "def init_LSTMl():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Masking layer to skip padding tokens\n",
    "    model.add(Masking())\n",
    "\n",
    "    # LSTM layer\n",
    "    model.add(layers.LSTM(20, activation='tanh'))\n",
    "\n",
    "    # Dense hidden layer\n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "\n",
    "    # Output layer for binary classification\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['precision'])\n",
    "\n",
    "    return model\n",
    "\n",
    "LSTM_model = init_LSTMl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bb23c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 12:08:26.067639: E tensorflow/core/util/util.cc:131] oneDNN supports DT_BOOL only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 293ms/step - loss: 0.6838 - precision: 0.5169 - val_loss: 0.6805 - val_precision: 0.7945\n",
      "Epoch 2/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 282ms/step - loss: 0.6693 - precision: 0.6774 - val_loss: 0.6803 - val_precision: 0.7188\n",
      "Epoch 3/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 255ms/step - loss: 0.6716 - precision: 0.6659 - val_loss: 0.6747 - val_precision: 0.5740\n",
      "Epoch 4/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 245ms/step - loss: 0.6666 - precision: 0.6242 - val_loss: 0.6709 - val_precision: 0.5920\n",
      "Epoch 5/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 247ms/step - loss: 0.6657 - precision: 0.6039 - val_loss: 0.6733 - val_precision: 0.5378\n",
      "Epoch 6/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 245ms/step - loss: 0.6618 - precision: 0.6071 - val_loss: 0.6674 - val_precision: 0.5367\n",
      "Epoch 7/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 249ms/step - loss: 0.6503 - precision: 0.6113 - val_loss: 0.6686 - val_precision: 0.5167\n",
      "Epoch 8/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 225ms/step - loss: 0.6538 - precision: 0.5985 - val_loss: 0.6554 - val_precision: 0.6200\n",
      "Epoch 9/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 243ms/step - loss: 0.6485 - precision: 0.6366 - val_loss: 0.6551 - val_precision: 0.5668\n",
      "Epoch 10/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 241ms/step - loss: 0.6442 - precision: 0.6400 - val_loss: 0.6698 - val_precision: 0.5738\n",
      "Epoch 11/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 252ms/step - loss: 0.6598 - precision: 0.5974 - val_loss: 0.6631 - val_precision: 0.5464\n",
      "Epoch 12/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 243ms/step - loss: 0.6428 - precision: 0.6237 - val_loss: 0.6684 - val_precision: 0.5284\n",
      "Epoch 13/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 249ms/step - loss: 0.6387 - precision: 0.5955 - val_loss: 0.6517 - val_precision: 0.5674\n",
      "Epoch 14/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 253ms/step - loss: 0.6208 - precision: 0.6016 - val_loss: 0.6431 - val_precision: 0.5951\n",
      "Epoch 15/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 246ms/step - loss: 0.6200 - precision: 0.6261 - val_loss: 0.6343 - val_precision: 0.6376\n",
      "Epoch 16/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 248ms/step - loss: 0.6236 - precision: 0.6507 - val_loss: 0.6427 - val_precision: 0.5672\n",
      "Epoch 17/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 252ms/step - loss: 0.6047 - precision: 0.6613 - val_loss: 0.6318 - val_precision: 0.6079\n",
      "Epoch 18/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 252ms/step - loss: 0.6051 - precision: 0.6292 - val_loss: 0.6403 - val_precision: 0.5736\n",
      "Epoch 19/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 218ms/step - loss: 0.6033 - precision: 0.6396 - val_loss: 0.6802 - val_precision: 0.7553\n",
      "Epoch 20/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 89ms/step - loss: 0.6022 - precision: 0.6674 - val_loss: 0.6292 - val_precision: 0.6808\n",
      "Epoch 21/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 86ms/step - loss: 0.6022 - precision: 0.6459 - val_loss: 0.6227 - val_precision: 0.6278\n",
      "Epoch 22/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 87ms/step - loss: 0.5808 - precision: 0.6721 - val_loss: 0.6272 - val_precision: 0.6810\n",
      "Epoch 23/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - loss: 0.5827 - precision: 0.6770 - val_loss: 0.6399 - val_precision: 0.7200\n",
      "Epoch 24/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 86ms/step - loss: 0.5703 - precision: 0.6782 - val_loss: 0.6416 - val_precision: 0.7225\n",
      "Epoch 25/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - loss: 0.5716 - precision: 0.6924 - val_loss: 0.6232 - val_precision: 0.6694\n",
      "Epoch 26/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - loss: 0.5614 - precision: 0.6873 - val_loss: 0.6247 - val_precision: 0.6941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f6c640de110>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "LSTM_model.fit(X_train_pad, y_train, \n",
    "          batch_size = 32,\n",
    "          epochs=100,\n",
    "          validation_split=0.5,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6509e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision evaluated on the test set is of 61.982%\n"
     ]
    }
   ],
   "source": [
    "res = LSTM_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(f'The precision evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7352414",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85926ca1",
   "metadata": {},
   "source": [
    "## FinBert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1aee99",
   "metadata": {},
   "source": [
    "## Roberta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
